# CV Evaluator - Sistema de EvaluaciÃ³n de Candidatos con IA

## ğŸ“‹ DescripciÃ³n General

**CV Evaluator** es un sistema basado en LLM (Large Language Models) que automatiza la evaluaciÃ³n de candidatos comparando sus CVs contra los requisitos de una oferta de trabajo. El sistema estÃ¡ construido con **LangChain** para la orquestaciÃ³n de LLMs, **LangSmith** para el tracking de ejecuciones, y **DeepEval** para la evaluaciÃ³n de calidad del sistema.

![Frontend con Streamlit](data/frontend.png)


---

## ğŸ¯ Funcionalidad Principal

El sistema opera en **dos fases**:

### Fase 1: EvaluaciÃ³n AutomÃ¡tica CV-Oferta

1. **ExtracciÃ³n de Requisitos**: Analiza la oferta de trabajo y extrae todos los requisitos, clasificÃ¡ndolos como:
   - **Obligatorios**: Requisitos mÃ­nimos/imprescindibles (palabras clave: "mÃ­nimo", "requerido", "necesario")
   - **Opcionales**: Requisitos deseables (palabras clave: "valorable", "deseable", "plus")

2. **Matching CV-Requisitos**: Compara el CV del candidato contra cada requisito y los clasifica en:
   - `matching_requirements`: Requisitos que el CV demuestra cumplir
   - `unmatching_requirements`: Requisitos que el CV no cumple o contradice
   - `to_verify`: Requisitos que podrÃ­an cumplirse pero requieren verificaciÃ³n

3. **CÃ¡lculo de PuntuaciÃ³n**:
   - Score = (requisitos cumplidos / total requisitos) Ã— 100
   - Si falla un requisito **obligatorio** â†’ `discarded: true`, `score: 0`

### Fase 2: Entrevista de VerificaciÃ³n

Si el candidato no estÃ¡ descartado y tiene requisitos en `to_verify`:

1. **GeneraciÃ³n de Preguntas**: El sistema genera preguntas especÃ­ficas para cada requisito pendiente
2. **Procesamiento de Respuestas**: Interpreta las respuestas del candidato (confirmed/denied/unclear)
3. **ActualizaciÃ³n de EvaluaciÃ³n**: Recalcula el score con la nueva informaciÃ³n

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CV EVALUATOR SYSTEM                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   INPUTS     â”‚    â”‚   CORE       â”‚    â”‚   OUTPUTS    â”‚          â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚          â”‚
â”‚  â”‚  â€¢ Oferta    â”‚â”€â”€â”€â–¶â”‚  LangChain   â”‚â”€â”€â”€â–¶â”‚  EvaluaciÃ³n  â”‚          â”‚
â”‚  â”‚  â€¢ CV        â”‚    â”‚  + LLM       â”‚    â”‚  JSON        â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                             â”‚                                       â”‚
â”‚                             â–¼                                       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                    â”‚  LangSmith   â”‚                                 â”‚
â”‚                    â”‚  (Tracking)  â”‚                                 â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      EVALUATION LAYER                               â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      DeepEval                                 â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  â€¢ requirement_extraction_correctness (GEval)                â”‚  â”‚
â”‚  â”‚  â€¢ cv_faithfulness (GEval)                                   â”‚  â”‚
â”‚  â”‚  â€¢ evaluation_hallucination (GEval)                          â”‚  â”‚
â”‚  â”‚  â€¢ interview_completeness (GEval)                            â”‚  â”‚
â”‚  â”‚  â€¢ interview_faithfulness (GEval)                            â”‚  â”‚
â”‚  â”‚  â€¢ interview_hallucination (GEval)                           â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â”‚                                       â”‚
â”‚                             â–¼                                       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                    â”‚ Confident AI â”‚                                 â”‚
â”‚                    â”‚ (Dashboard)  â”‚                                 â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Estructura del Proyecto

```
cv-evaluator/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ prompts.py           # Archivo con los diferentes prompts para cada cadena
â”‚   â””â”€â”€ settings.py          # ConfiguraciÃ³n y variables de entorno
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ evaluator.py         # LÃ³gica de evaluaciÃ³n CV-Oferta (Fase 1)
â”‚   â”œâ”€â”€ llm.py               # Carga del modelo LLM
â”‚   â””â”€â”€ interviewer.py       # LÃ³gica de entrevista (Fase 2)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py        # Modelos Pydantic (EvaluationResult)
|
â”œâ”€â”€ evaluation/              # Tests con DeepEval
â”‚   â”œâ”€â”€ conftest.py          # ConfiguraciÃ³n pytest/deepeval
â”‚   â”œâ”€â”€ test_fase1_evaluator.py
â”‚   â”œâ”€â”€ test_fase2_end_to_end.py
â”‚   â”œâ”€â”€ data/                # CVs y ofertas de prueba
â”‚   â”œâ”€â”€ ground_truth/        # Expected outputs
â”‚   â””â”€â”€ metrics/
â”‚       â””â”€â”€ custom_metrics.py  # MÃ©tricas GEval personalizadas
â”œâ”€â”€ data/                    # Datos de la aplicaciÃ³n (ejemplos de Ofertas)
â”œâ”€â”€ streamlit_app.py                   # AplicaciÃ³n Streamlit
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile               # Archivos Docker para local y cloud (AWS previsto y desestimado)
â”œâ”€â”€ Dockerfile_local         
â””â”€â”€ .env                     # Variables de entorno
```

---

## ğŸ”§ Stack TecnolÃ³gico

| Componente | TecnologÃ­a | PropÃ³sito |
|------------|------------|-----------|
| **OrquestaciÃ³n LLM** | LangChain | GestiÃ³n de prompts, chains y structured output |
| **Modelo LLM** | OpenAI GPT-4o-mini | EvaluaciÃ³n y generaciÃ³n de respuestas |
| **Tracking** | LangSmith | Monitoreo de ejecuciones, costes y latencia |
| **EvaluaciÃ³n** | DeepEval + GEval | Testing de calidad del sistema LLM |
| **Dashboard** | Confident AI | VisualizaciÃ³n de resultados de evaluaciÃ³n |
| **UI** | Streamlit | Interfaz de usuario |


---

## ğŸ” Sistema de Tracking con LangSmith

LangSmith proporciona observabilidad completa del sistema:

### QuÃ© se trackea:
- **Traces**: Cada ejecuciÃ³n completa del evaluador
- **Spans**: Llamadas individuales al LLM
- **Inputs/Outputs**: Prompts enviados y respuestas recibidas
- **MÃ©tricas**: Latencia, tokens consumidos, coste estimado
- **Errores**: Fallos y excepciones

![LangSmith](data/langsmith.png)


## âœ… Sistema de EvaluaciÃ³n con DeepEval

DeepEval evalÃºa la calidad del sistema usando mÃ©tricas LLM-as-a-Judge (GEval).

![deepeval_summary](data/deepeval_summary.png)

### MÃ©tricas Fase 1 (Evaluador CV-Oferta):

| MÃ©trica | Threshold | QuÃ© evalÃºa |
|---------|-----------|------------|
| `requirement_extraction_correctness` | 0.5 | Â¿Se extrajeron correctamente los requisitos de la oferta? |
| `cv_faithfulness` | 0.5 | Â¿Los requisitos "cumplidos" estÃ¡n evidenciados en el CV? |
| `evaluation_hallucination` | 0.8 | Â¿El sistema inventÃ³ informaciÃ³n no presente en los inputs? |

### MÃ©tricas Fase 2 (Entrevista):

| MÃ©trica | Threshold | QuÃ© evalÃºa |
|---------|-----------|------------|
| `interview_completeness` | 0.8 | Â¿Se preguntÃ³ por todos los requisitos pendientes? |
| `interview_faithfulness` | 0.8 | Â¿El resultado es coherente con las respuestas del candidato? |
| `interview_hallucination` | 0.8 | Â¿Se inventaron confirmaciones o negaciones? |

![deepeval_detail](data/deepeval_detail.png)

### EjecuciÃ³n de Tests:
```bash
# Ejecutar toda las evaluaciones con identificador para tracking
deepeval test run evaluation/ --identifier "input_id"

```

### VisualizaciÃ³n:
Los resultados se suben automÃ¡ticamente a **Confident AI** para visualizaciÃ³n en dashboard.

---

## ğŸ“Š Formato de Salida (EvaluationResult)

```json
{
  "total_requirements": 9,
  "Ls_total_requirements": ["Req 1", "Req 2", ...],
  "Ls_mandatory_requirements": ["Req obligatorio 1", ...],
  "Ls_optional_requirements": ["Req opcional 1", ...],
  "score": 77.78,
  "discarded": false,
  "matching_requirements": ["Req cumplido 1", ...],
  "unmatching_requirements": ["Req no cumplido 1", ...],
  "to_verify": ["Req a verificar 1", ...]
}
```

---

## ğŸš€ Quick Start

### 1. InstalaciÃ³n:
```bash
pip install -r requirements.txt
```

### 2. Configurar .env con tus API keys

### 3. Ejecutar la aplicaciÃ³n:
```bash
streamlit run streamlit_app/app.py
```

### 4. Ejecutar evaluaciÃ³n:
```bash
deepeval test run evaluation/
```

---

## ğŸ“ˆ Roadmap a futuro

- [ ] API REST para integraciÃ³n en FastAPI y productivizar en algun Cloud

---

## ğŸ‘¥ Autores

Alejandro SÃ¡nchez Silvestre - Dic 2025

---

## ğŸ“„ Licencia

MIT - License
